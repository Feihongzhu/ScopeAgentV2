"""
ScopeThinkAgent - æ ¸å¿ƒåˆ†æAgent
"""

import time
from datetime import datetime
from typing import Dict, Any, List, Optional
from langchain.llms.base import BaseLLM
from langchain.chains import LLMChain

from ..models.analysis_models import (
    ProblemType, ThinkStep, AnalysisResult, ContextInfo, 
    IterationState, ThinkStepResult
)
from ..prompts.main_think_prompt import MainThinkPromptTemplate
from ..tools.file_reader import FileReaderTool, SmartFileReader
from ..tools.file_recommendation import FileRecommendationTool
from ..tools.iterative_feedback import IterativeFeedbackProcessor
from .base_agent import BaseThinkAgent


class ScopeThinkAgent(BaseThinkAgent):
    """SCOPEä½œä¸šåˆ†æçš„æ™ºèƒ½Agent"""
    
    def __init__(self, 
                 llm: BaseLLM,
                 file_reader: FileReaderTool,
                 recommendation_tool: FileRecommendationTool,
                 max_iterations: int = 5):
        """
        åˆå§‹åŒ–ScopeThinkAgent
        
        Args:
            llm: è¯­è¨€æ¨¡å‹
            file_reader: æ–‡ä»¶è¯»å–å·¥å…·
            recommendation_tool: æ–‡ä»¶æ¨èå·¥å…·
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        """
        super().__init__(llm, max_iterations)
        
        self.file_reader = file_reader
        self.recommendation_tool = recommendation_tool
        self.smart_reader = SmartFileReader(file_reader, recommendation_tool)
        self.feedback_processor = IterativeFeedbackProcessor(recommendation_tool)
        
        # åˆå§‹åŒ–Promptæ¨¡æ¿
        self.main_prompt = MainThinkPromptTemplate()
        
        # åˆå§‹åŒ–LLMé“¾
        self.analysis_chain = LLMChain(
            llm=self.llm,
            prompt=self.main_prompt.prompt,
            verbose=True
        )
        
    def analyze(self, user_question: str, context_info: Optional[Dict] = None) -> AnalysisResult:
        """
        ä¸»è¦åˆ†ææ–¹æ³•
        
        Args:
            user_question: ç”¨æˆ·é—®é¢˜
            context_info: é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            åˆ†æç»“æœ
        """
        start_time = time.time()
        
        # åˆå§‹åŒ–ä¸Šä¸‹æ–‡
        context = ContextInfo(
            user_input=user_question,
            current_analysis="",
            files_read=[],
            key_findings=[]
        )
        
        # åˆå§‹åŒ–è¿­ä»£çŠ¶æ€
        iteration_state = IterationState(max_iterations=self.max_iterations)
        
        think_results = []
        files_analyzed = []
        
        try:
            # ç¬¬ä¸€æ¬¡è¿­ä»£å‰ï¼Œå…ˆè¯»å–ä¸€äº›å…³é”®æ–‡ä»¶
            if not context.files_read:
                print("\nğŸ“„ è‡ªåŠ¨è¯»å–å…³é”®æ–‡ä»¶...")
                initial_files = self._get_initial_files_to_read()
                for file_name in initial_files:
                    try:
                        file_content = self.file_reader.read_file(file_name)
                        context.files_read.append(file_name)
                        context.current_analysis += f"\n\n=== {file_name} å†…å®¹ ===\n{file_content}"
                        files_analyzed.append(file_name)
                        print(f"   âœ… è¯»å– {file_name}")
                    except Exception as e:
                        print(f"   âŒ æ— æ³•è¯»å– {file_name}: {str(e)}")
            
            # è¿­ä»£åˆ†æè¿‡ç¨‹
            while iteration_state.can_continue():
                iteration_state.increment_iteration()
                
                # æ„é€ å½“å‰åˆ†æçš„è¾“å…¥
                analysis_input = self._build_analysis_input(
                    user_question, context, iteration_state
                )
                
                # æ‰§è¡ŒLLMåˆ†æ
                result = self.analysis_chain.invoke(analysis_input)
                
                # è°ƒè¯•è¾“å‡º
                print(f"\nğŸ” è°ƒè¯•ä¿¡æ¯:")
                print(f"LLMè¿”å›ç±»å‹: {type(result)}")
                print(f"LLMè¿”å›é”®: {list(result.keys()) if isinstance(result, dict) else 'N/A'}")
                
                # å°è¯•ä¸åŒçš„è§£ææ–¹å¼
                if isinstance(result, dict):
                    if "text" in result:
                        response = result["text"]
                    elif "content" in result:
                        response = result["content"]
                    else:
                        # å–ç¬¬ä¸€ä¸ªå­—ç¬¦ä¸²å€¼
                        response = next((v for v in result.values() if isinstance(v, str)), str(result))
                else:
                    response = str(result)
                
                print(f"è§£æåå“åº”é•¿åº¦: {len(response)}")
                print(f"å“åº”å‰100å­—ç¬¦: {response[:100]}...")
                print("="*50)
                
                # è§£æåˆ†æç»“æœ
                step_results = self._parse_think_steps(response)
                think_results.extend(step_results)
                
                # æ›´æ–°ä¸Šä¸‹æ–‡
                context.current_analysis += f"\n\n=== è¿­ä»£ {iteration_state.iteration_count} ===\n{response}"
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦è¯»å–æ›´å¤šæ–‡ä»¶
                think4_result = self._get_step_result(step_results, ThinkStep.INFO_COMPLETENESS)
                
                if think4_result and think4_result.needs_more_info:
                    # æ™ºèƒ½è¯»å–æ–‡ä»¶
                    read_result = self._smart_read_files(
                        context, iteration_state, think4_result
                    )
                    
                    if read_result["success"]:
                        files_analyzed.extend(read_result["files_read"])
                        context.files_read.extend(read_result["files_read"])
                        context.current_analysis += f"\n\n=== æ–‡ä»¶å†…å®¹ ===\n{read_result['content']}"
                    else:
                        # å¦‚æœæ— æ³•è¯»å–æ›´å¤šæ–‡ä»¶ï¼Œåˆ™åœæ­¢è¿­ä»£
                        iteration_state.information_sufficient = True
                else:
                    # å¦‚æœä¸éœ€è¦æ›´å¤šä¿¡æ¯ï¼Œåˆ™ç»“æŸè¿­ä»£
                    iteration_state.information_sufficient = True
            
            # æå–æœ€ç»ˆè§£å†³æ–¹æ¡ˆ
            final_solution = self._extract_final_solution(think_results)
            
            # ç¡®å®šé—®é¢˜ç±»å‹
            problem_type = self._determine_problem_type(think_results)
            
            # è®¡ç®—ç½®ä¿¡åº¦
            confidence_score = self._calculate_confidence(think_results, iteration_state)
            
        except Exception as e:
            # é”™è¯¯å¤„ç†
            final_solution = f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            problem_type = ProblemType.OTHER
            confidence_score = 0.0
        
        processing_time = time.time() - start_time
        
        return AnalysisResult(
            problem_type=problem_type,
            think_steps=think_results,
            final_solution=final_solution,
            confidence_score=confidence_score,
            files_analyzed=files_analyzed,
            processing_time=processing_time,
            timestamp=datetime.now()
        )
    
    def _build_analysis_input(self, user_question: str, context: ContextInfo, 
                             iteration_state: IterationState) -> Dict[str, Any]:
        """æ„å»ºåˆ†æè¾“å…¥"""
        return {
            "user_question": user_question,
            "context_info": self._format_context_info(context),
            "retrieved_experience": self._get_relevant_experience(user_question, context),
            "files_content": self._format_files_content(context),
            "problem_type": context.problem_type.value if context.problem_type else "æœªç¡®å®š",
            "components": ", ".join(context.key_findings),
            "user_description": user_question
        }
    
    def _format_context_info(self, context: ContextInfo) -> str:
        """æ ¼å¼åŒ–ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        info_parts = []
        
        if context.problem_type:
            info_parts.append(f"é—®é¢˜ç±»å‹: {context.problem_type.value}")
        
        if context.files_read:
            info_parts.append(f"å·²è¯»å–æ–‡ä»¶: {', '.join(context.files_read)}")
        
        if context.key_findings:
            info_parts.append(f"å…³é”®å‘ç°: {'; '.join(context.key_findings)}")
        
        return "\n".join(info_parts) if info_parts else "æš‚æ— ä¸Šä¸‹æ–‡ä¿¡æ¯"
    
    def _get_relevant_experience(self, question: str, context: ContextInfo) -> str:
        """è·å–ç›¸å…³ç»éªŒçŸ¥è¯†ï¼ˆç®€åŒ–å®ç°ï¼‰"""
        # è¿™é‡Œå¯ä»¥æ¥å…¥RAGç³»ç»Ÿæˆ–çŸ¥è¯†åº“
        base_experience = """
        [æ•°æ®å€¾æ–œä¼˜åŒ–ç»éªŒ]
        1. ä½¿ç”¨PartitionByåˆç†é‡æ–°åˆ†åŒº
        2. çƒ­ç‚¹é”®å•ç‹¬å¤„ç†æˆ–åŠ éšæœºç›å€¼
        3. é¿å…è¿‡åº¦é›†ä¸­çš„Joiné”®
        
        [Shuffleä¼˜åŒ–ç»éªŒ]
        1. åˆç†åˆ©ç”¨PartitionByå‡å°‘é‡å¤Shuffle
        2. æå‰æŠ•å½±å‡å°‘æ•°æ®è§„æ¨¡
        3. é¿å…å¤šæ¬¡å…¨ç½‘é‡åˆ†å¸ƒ
        4. ä½¿ç”¨å¹¿æ’­Joinå¤„ç†å°è¡¨
        """
        return base_experience
    
    def _format_files_content(self, context: ContextInfo) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å†…å®¹"""
        if not context.current_analysis:
            return "æš‚æ— æ–‡ä»¶å†…å®¹"
        
        # æå–æ–‡ä»¶ç›¸å…³éƒ¨åˆ†
        parts = context.current_analysis.split("=== æ–‡ä»¶å†…å®¹ ===")
        if len(parts) > 1:
            return parts[-1]
        return "æš‚æ— æ–‡ä»¶å†…å®¹"
    
    def _parse_think_steps(self, response: str) -> List[ThinkStepResult]:
        """è§£ææ€è€ƒæ­¥éª¤ç»“æœ"""
        steps = []
        
        # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„THINKæ­¥éª¤æ ¼å¼
        think_patterns = {
            ThinkStep.PROBLEM_CLASSIFICATION: "[THINK 1]",
            ThinkStep.CODE_ANALYSIS: "[THINK 2]", 
            ThinkStep.EXPERIENCE_ANALYSIS: "[THINK 3]",
            ThinkStep.INFO_COMPLETENESS: "[THINK 4]",
            ThinkStep.FINAL_SOLUTION: "[THINK 5]"
        }
        
        print(f"\nğŸ” è§£æTHINKæ­¥éª¤...")
        print(f"å“åº”é•¿åº¦: {len(response)}")
        
        for step, pattern in think_patterns.items():
            if pattern in response:
                print(f"âœ… æ‰¾åˆ° {pattern}")
                
                # æå–è¯¥æ­¥éª¤çš„å†…å®¹
                start_idx = response.find(pattern)
                
                # å¯»æ‰¾ä¸‹ä¸€ä¸ªæ­¥éª¤çš„å¼€å§‹
                next_step_idx = len(response)
                for other_step, other_pattern in think_patterns.items():
                    if other_step != step and other_pattern in response:
                        other_idx = response.find(other_pattern)
                        if other_idx > start_idx and other_idx < next_step_idx:
                            next_step_idx = other_idx
                
                content = response[start_idx:next_step_idx].strip()
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´å¤šä¿¡æ¯
                needs_more_info = ("éœ€è¦æ–‡ä»¶" in content and "æ˜¯" in content) or "ã€éœ€è¦æ–‡ä»¶ã€‘: æ˜¯" in content
                
                print(f"   å†…å®¹é•¿åº¦: {len(content)}")
                print(f"   éœ€è¦æ›´å¤šä¿¡æ¯: {needs_more_info}")
                
                step_result = ThinkStepResult(
                    step=step,
                    content=content,
                    confidence=self._estimate_step_confidence(content),
                    needs_more_info=needs_more_info
                )
                
                steps.append(step_result)
            else:
                print(f"âŒ æœªæ‰¾åˆ° {pattern}")
        
        print(f"æ€»å…±è§£æåˆ° {len(steps)} ä¸ªæ­¥éª¤")
        return steps
    
    def _smart_read_files(self, context: ContextInfo, iteration_state: IterationState,
                         think4_result: ThinkStepResult) -> Dict[str, Any]:
        """æ™ºèƒ½è¯»å–æ–‡ä»¶"""
        try:
            # ä½¿ç”¨æ™ºèƒ½æ–‡ä»¶è¯»å–å™¨
            read_result = self.smart_reader.smart_read(
                problem_type=context.problem_type or ProblemType.OTHER,
                context=context,
                current_analysis=context.current_analysis,
                max_files=3
            )
            
            return read_result
            
        except Exception as e:
            return {
                "success": False,
                "message": f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}",
                "files_read": [],
                "content": ""
            }
    
    def _get_step_result(self, step_results: List[ThinkStepResult], 
                        target_step: ThinkStep) -> Optional[ThinkStepResult]:
        """è·å–ç‰¹å®šæ­¥éª¤çš„ç»“æœ"""
        for result in step_results:
            if result.step == target_step:
                return result
        return None
    
    def _extract_final_solution(self, think_results: List[ThinkStepResult]) -> str:
        """æå–æœ€ç»ˆè§£å†³æ–¹æ¡ˆ"""
        think5_result = self._get_step_result(think_results, ThinkStep.FINAL_SOLUTION)
        if think5_result:
            return think5_result.content
        
        # å¦‚æœæ²¡æœ‰THINK 5ï¼Œåˆ™æ±‡æ€»å…¶ä»–æ­¥éª¤
        solution_parts = []
        for result in think_results:
            if result.step in [ThinkStep.EXPERIENCE_ANALYSIS, ThinkStep.CODE_ANALYSIS]:
                solution_parts.append(f"{result.step.value}: {result.content[:200]}...")
        
        return "\n\n".join(solution_parts) if solution_parts else "æ— æ³•ç”Ÿæˆè§£å†³æ–¹æ¡ˆ"
    
    def _determine_problem_type(self, think_results: List[ThinkStepResult]) -> ProblemType:
        """ç¡®å®šé—®é¢˜ç±»å‹"""
        think1_result = self._get_step_result(think_results, ThinkStep.PROBLEM_CLASSIFICATION)
        if think1_result:
            content = think1_result.content.lower()
            if "æ•°æ®å€¾æ–œ" in content:
                return ProblemType.DATA_SKEW
            elif "shuffle" in content or "é‡åˆ†å¸ƒ" in content:
                return ProblemType.EXCESSIVE_SHUFFLE
        
        return ProblemType.OTHER
    
    def _calculate_confidence(self, think_results: List[ThinkStepResult], 
                            iteration_state: IterationState) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦"""
        if not think_results:
            return 0.0
        
        # åŸºäºæ­¥éª¤å®Œæ•´æ€§å’Œå†…å®¹è´¨é‡è®¡ç®—
        step_scores = [result.confidence for result in think_results]
        base_confidence = sum(step_scores) / len(step_scores)
        
        # æ ¹æ®è¿­ä»£æ¬¡æ•°è°ƒæ•´
        iteration_penalty = (iteration_state.iteration_count - 1) * 0.1
        
        return max(0.0, min(1.0, base_confidence - iteration_penalty))
    
    def _estimate_step_confidence(self, content: str) -> float:
        """ä¼°ç®—å•ä¸ªæ­¥éª¤çš„ç½®ä¿¡åº¦"""
        # åŸºäºå†…å®¹é•¿åº¦å’Œå…³é”®è¯ä¼°ç®—
        if len(content) < 50:
            return 0.3
        elif len(content) < 200:
            return 0.6
        else:
            return 0.8
    
    def _get_initial_files_to_read(self) -> List[str]:
        """è·å–åˆå§‹åº”è¯¥è¯»å–çš„å…³é”®æ–‡ä»¶"""
        # åŸºäºä¼˜å…ˆçº§è¯»å–æœ€é‡è¦çš„æ–‡ä»¶
        priority_files = [
            "Error",  # é”™è¯¯ä¿¡æ¯æœ€é‡è¦
            "request.script",  # ç”¨æˆ·è„šæœ¬
            "__Warnings__.xml",  # è­¦å‘Šä¿¡æ¯
            "JobStatistics.xml",  # ä½œä¸šç»Ÿè®¡
        ]
        
        return priority_files 