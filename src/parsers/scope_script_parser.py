"""
SCOPEè„šæœ¬è§£æå™¨ - è§£æSCOPEè„šæœ¬æ–‡ä»¶
"""

import re


def parse_scope_script(file_path: str) -> str:
    """è§£æ SCOPE è„šæœ¬æ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        summary = ["SCOPEè„šæœ¬åˆ†æ:"]
        
        lines = content.split('\n')
        total_lines = len(lines)
        
        # åŸºæœ¬ç»Ÿè®¡
        summary.append(f"- è„šæœ¬è¡Œæ•°: {total_lines}")
        
        # åˆ†ææ¨¡å—å’Œå¼•ç”¨
        module_count, reference_count, dll_references = _analyze_modules_and_references(content)
        summary.append(f"- MODULEå¼•ç”¨: {module_count}")
        summary.append(f"- REFERENCEå¼•ç”¨: {reference_count}")
        if dll_references:
            summary.append(f"- DLLæ–‡ä»¶: {', '.join(dll_references[:3])}{'...' if len(dll_references) > 3 else ''}")
        
        # åˆ†æå˜é‡å£°æ˜
        declare_count = _count_pattern(content, r'#DECLARE\s+\w+')
        summary.append(f"- å˜é‡å£°æ˜: {declare_count}")
        
        # åˆ†æVIEWä½¿ç”¨
        view_count = _count_pattern(content, r'VIEW\s+"[^"]+\.view"')
        summary.append(f"- VIEWä½¿ç”¨: {view_count}")
        
        # åˆ†æSQLæ“ä½œ
        sql_stats = _analyze_sql_operations(content)
        summary.append(f"- SELECTè¯­å¥: {sql_stats['select']}")
        summary.append(f"- JOINæ“ä½œ: {sql_stats['total_joins']}")
        summary.append(f"- GROUP BYæ“ä½œ: {sql_stats['group_by']}")
        summary.append(f"- PARTITION BYæ“ä½œ: {sql_stats['partition_by']}")
        
        # JOINç±»å‹è¯¦ç»†åˆ†æ
        join_details = _analyze_join_types(content)
        if join_details:
            summary.append("- JOINç±»å‹åˆ†å¸ƒ:")
            for join_type, count in join_details.items():
                summary.append(f"  {join_type}: {count}")
        
        # åˆ†æèšåˆå‡½æ•°
        agg_functions = _analyze_aggregation_functions(content)
        if agg_functions:
            summary.append("- èšåˆå‡½æ•°:")
            for func, count in agg_functions.items():
                summary.append(f"  {func}: {count}")
        
        # åˆ†æUDFå’Œè‡ªå®šä¹‰å¤„ç†å™¨
        udf_stats = _analyze_udf_and_processors(content)
        if udf_stats['cs_blocks'] > 0:
            summary.append(f"- C#ä»£ç å—: {udf_stats['cs_blocks']}")
        if udf_stats['processors']:
            summary.append(f"- è‡ªå®šä¹‰å¤„ç†å™¨: {', '.join(udf_stats['processors'])}")
        
        # åˆ†æSETé…ç½®
        set_configs = _analyze_set_configurations(content)
        if set_configs:
            summary.append("- æ€§èƒ½é…ç½®:")
            for config in set_configs:
                summary.append(f"  {config}")
        
        # åˆ†æå¤æ‚æ“ä½œ
        complex_ops = _analyze_complex_operations(content)
        if complex_ops:
            summary.append("- å¤æ‚æ“ä½œ:")
            for op in complex_ops:
                summary.append(f"  - {op}")
        
        # æ½œåœ¨æ€§èƒ½é—®é¢˜æ£€æµ‹
        issues = _detect_performance_issues(content, sql_stats, join_details, udf_stats)
        if issues:
            summary.append("- æ½œåœ¨æ€§èƒ½é—®é¢˜:")
            for issue in issues:
                summary.append(f"  âš ï¸ {issue}")
        
        # æ€§èƒ½å»ºè®®
        recommendations = _generate_recommendations(sql_stats, join_details, udf_stats, set_configs)
        if recommendations:
            summary.append("- æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
            for rec in recommendations:
                summary.append(f"  ğŸ’¡ {rec}")
        
        return "\n".join(summary)
    except Exception as e:
        return f"è§£æSCOPEè„šæœ¬å¤±è´¥: {str(e)}"


def _analyze_modules_and_references(content: str) -> tuple:
    """åˆ†ææ¨¡å—å’Œå¼•ç”¨"""
    module_count = _count_pattern(content, r'MODULE\s+"[^"]+"')
    reference_count = _count_pattern(content, r'\[PIN\]REFERENCE\s+"[^"]+"')
    
    # æå–DLLå¼•ç”¨
    dll_pattern = r'\[PIN\]REFERENCE\s+"[^"]*\.dll"'
    dll_matches = re.findall(dll_pattern, content, re.IGNORECASE)
    dll_references = [match.split('/')[-1].replace('"', '') for match in dll_matches]
    
    return module_count, reference_count, dll_references


def _analyze_sql_operations(content: str) -> dict:
    """åˆ†æSQLæ“ä½œ"""
    return {
        'select': _count_pattern(content, r'\bSELECT\b'),
        'total_joins': _count_pattern(content, r'\bJOIN\b'),
        'group_by': _count_pattern(content, r'\bGROUP\s+BY\b'),
        'partition_by': _count_pattern(content, r'\bPARTITION\s+BY\b')
    }


def _analyze_join_types(content: str) -> dict:
    """åˆ†æJOINç±»å‹"""
    join_types = {
        'INNER JOIN': _count_pattern(content, r'\bINNER\s+JOIN\b'),
        'LEFT JOIN': _count_pattern(content, r'\bLEFT\s+JOIN\b'),
        'RIGHT JOIN': _count_pattern(content, r'\bRIGHT\s+JOIN\b'),
        'FULL JOIN': _count_pattern(content, r'\bFULL\s+JOIN\b'),
        'CROSS JOIN': _count_pattern(content, r'\bCROSS\s+JOIN\b'),
        'BROADCASTRIGHT JOIN': _count_pattern(content, r'\bBROADCASTRIGHT\s+JOIN\b'),
        'ANTISEMIJOIN': _count_pattern(content, r'\bANTISEMIJOIN\b'),
        'SEMIJOIN': _count_pattern(content, r'\bSEMIJOIN\b'),
        'æ™®é€šJOIN': _count_pattern(content, r'(?<!INNER\s)(?<!LEFT\s)(?<!RIGHT\s)(?<!FULL\s)(?<!CROSS\s)(?<!BROADCASTRIGHT\s)(?<!ANTI)(?<!SEMI)\bJOIN\b')
    }
    
    return {k: v for k, v in join_types.items() if v > 0}


def _analyze_aggregation_functions(content: str) -> dict:
    """åˆ†æèšåˆå‡½æ•°"""
    agg_functions = {
        'COUNT': _count_pattern(content, r'\bCOUNT\s*\('),
        'COUNTIF': _count_pattern(content, r'\bCOUNTIF\s*\('),
        'SUM': _count_pattern(content, r'\bSUM\s*\('),
        'AVG': _count_pattern(content, r'\bAVG\s*\('),
        'MAX': _count_pattern(content, r'\bMAX\s*\('),
        'MIN': _count_pattern(content, r'\bMIN\s*\('),
        'LIST': _count_pattern(content, r'\bLIST\s*\('),
        'DISTINCT': _count_pattern(content, r'\bDISTINCT\b')
    }
    
    return {k: v for k, v in agg_functions.items() if v > 0}


def _analyze_udf_and_processors(content: str) -> dict:
    """åˆ†æUDFå’Œè‡ªå®šä¹‰å¤„ç†å™¨"""
    cs_blocks = len(re.findall(r'#CS.*?#ENDCS', content, re.DOTALL))
    
    # æŸ¥æ‰¾è‡ªå®šä¹‰å¤„ç†å™¨
    processor_pattern = r'USING\s+(\w+);'
    processors = re.findall(processor_pattern, content)
    processors = [p for p in processors if p not in ['Outputters', 'Privacy']]  # æ’é™¤ç³»ç»Ÿå¤„ç†å™¨
    
    return {
        'cs_blocks': cs_blocks,
        'processors': list(set(processors))  # å»é‡
    }


def _analyze_set_configurations(content: str) -> list:
    """åˆ†æSETé…ç½®"""
    set_patterns = [
        (r'SET\s+@@Buckets\s*=\s*(\d+)', 'Bucketsè®¾ç½®'),
        (r'SET\s+@@IgnoreMaxPartitionsThreshold\s*=\s*(\w+)', 'IgnoreMaxPartitionsThreshold'),
        (r'SET\s+@@FeaturePreviews\s*=\s*"([^"]+)"', 'FeaturePreviews'),
        (r'SET\s+@@(\w+)', 'å…¶ä»–SETé…ç½®')
    ]
    
    configs = []
    for pattern, description in set_patterns:
        matches = re.findall(pattern, content, re.IGNORECASE)
        if matches:
            if 'Buckets' in description:
                configs.append(f"{description}: {matches[0]}")
            elif matches[0]:
                configs.append(f"{description}: {matches[0]}")
            else:
                configs.append(description)
    
    return configs


def _analyze_complex_operations(content: str) -> list:
    """åˆ†æå¤æ‚æ“ä½œ"""
    complex_ops = []
    
    # CROSS APPLYæ“ä½œ
    if _count_pattern(content, r'\bCROSS\s+APPLY\b') > 0:
        complex_ops.append("CROSS APPLYæ“ä½œ")
    
    # PROCESSæ“ä½œ
    process_count = _count_pattern(content, r'\bPROCESS\b.*?\bUSING\b')
    if process_count > 0:
        complex_ops.append(f"PROCESSæ“ä½œ: {process_count}")
    
    # åµŒå¥—æŸ¥è¯¢
    nested_query_count = content.count('(') - content.count(')')
    if abs(nested_query_count) > 10:  # å¤§é‡åµŒå¥—
        complex_ops.append("å¤æ‚åµŒå¥—æŸ¥è¯¢")
    
    # UNIONæ“ä½œ
    union_count = _count_pattern(content, r'\bUNION\s+(ALL\s+)?')
    if union_count > 0:
        complex_ops.append(f"UNIONæ“ä½œ: {union_count}")
    
    return complex_ops


def _detect_performance_issues(content: str, sql_stats: dict, join_details: dict, udf_stats: dict) -> list:
    """æ£€æµ‹æ½œåœ¨æ€§èƒ½é—®é¢˜"""
    issues = []
    
    # JOINç›¸å…³é—®é¢˜
    if sql_stats['total_joins'] > 5:
        issues.append(f"è¿‡å¤šJOINæ“ä½œ({sql_stats['total_joins']}ä¸ª)ï¼Œå¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™")
    
    if 'CROSS JOIN' in join_details:
        issues.append("æ£€æµ‹åˆ°CROSS JOINï¼Œå¯èƒ½äº§ç”Ÿç¬›å¡å°”ç§¯")
    
    if sql_stats['total_joins'] > 0 and sql_stats['partition_by'] == 0:
        issues.append("æœ‰JOINæ“ä½œä½†æ— PARTITION BYï¼Œå¯èƒ½å¯¼è‡´æ•°æ®å€¾æ–œ")
    
    # èšåˆç›¸å…³é—®é¢˜
    if sql_stats['group_by'] > 3:
        issues.append(f"å¤šæ¬¡GROUP BYæ“ä½œ({sql_stats['group_by']}æ¬¡)ï¼Œå¯èƒ½å½±å“æ€§èƒ½")
    
    # UDFç›¸å…³é—®é¢˜
    if udf_stats['cs_blocks'] > 0:
        issues.append(f"åŒ…å«{udf_stats['cs_blocks']}ä¸ªC#ä»£ç å—ï¼ŒUDFå¯èƒ½å½±å“æ‰§è¡Œæ•ˆç‡")
    
    if len(udf_stats['processors']) > 2:
        issues.append("ä½¿ç”¨å¤šä¸ªè‡ªå®šä¹‰å¤„ç†å™¨ï¼Œå¯èƒ½å½±å“å¹¶è¡Œåº¦")
    
    # å¤æ‚æŸ¥è¯¢é—®é¢˜
    if _count_pattern(content, r'\bDISTINCT\b') > 3:
        issues.append("å¤šæ¬¡ä½¿ç”¨DISTINCTï¼Œå¯èƒ½éœ€è¦å¤§é‡å†…å­˜")
    
    # æ•°æ®å€¾æ–œé£é™©
    if 'string.Join' in content:
        issues.append("æ£€æµ‹åˆ°å­—ç¬¦ä¸²è¿æ¥æ“ä½œï¼Œæ³¨æ„å­—ç¬¦ä¸²é•¿åº¦é™åˆ¶")
    
    return issues


def _generate_recommendations(sql_stats: dict, join_details: dict, udf_stats: dict, set_configs: list) -> list:
    """ç”Ÿæˆæ€§èƒ½ä¼˜åŒ–å»ºè®®"""
    recommendations = []
    
    # JOINä¼˜åŒ–å»ºè®®
    if sql_stats['total_joins'] > 0 and sql_stats['partition_by'] == 0:
        recommendations.append("å»ºè®®æ·»åŠ PARTITION BYæ¥ä¼˜åŒ–JOINæ€§èƒ½")
    
    if 'BROADCASTRIGHT JOIN' not in join_details and sql_stats['total_joins'] > 2:
        recommendations.append("è€ƒè™‘ä½¿ç”¨BROADCASTRIGHT JOINä¼˜åŒ–å°è¡¨è¿æ¥")
    
    # èšåˆä¼˜åŒ–å»ºè®®
    if sql_stats['group_by'] > 1:
        recommendations.append("è€ƒè™‘åˆå¹¶GROUP BYæ“ä½œä»¥å‡å°‘ä¸­é—´ç»“æœ")
    
    # UDFä¼˜åŒ–å»ºè®®
    if udf_stats['cs_blocks'] > 0:
        recommendations.append("å®¡æŸ¥C#ä»£ç æ•ˆç‡ï¼Œè€ƒè™‘ä½¿ç”¨å†…ç½®å‡½æ•°æ›¿ä»£")
    
    # é…ç½®ä¼˜åŒ–å»ºè®®
    if not any('Buckets' in config for config in set_configs):
        recommendations.append("è€ƒè™‘è®¾ç½®@@Bucketså‚æ•°ä¼˜åŒ–å¹¶è¡Œåº¦")
    
    # å†…å­˜ä¼˜åŒ–å»ºè®®
    if _count_pattern(' '.join(set_configs), r'LIST\(') > 2:
        recommendations.append("æ³¨æ„LISTå‡½æ•°çš„å†…å­˜ä½¿ç”¨ï¼Œé¿å…è¿‡å¤§é›†åˆ")
    
    return recommendations


def _count_pattern(content: str, pattern: str) -> int:
    """ç»Ÿè®¡æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ¬¡æ•°"""
    return len(re.findall(pattern, content, re.IGNORECASE)) 